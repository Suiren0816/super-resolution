# #!/usr/bin/env python
# # -*- encoding: utf-8 -*-

import torch
from torch import nn
import torchvision
import math
import torchvision.models as models
import os


class ConvolutionalBlock(nn.Module):
    """
    å·ç§¯æ¨¡å—,ç”±å·ç§¯å±‚, BNå½’ä¸€åŒ–å±‚, æ¿€æ´»å±‚æ„æˆ.
    """

    def __init__(self, in_channels, out_channels, kernel_size, stride=1, activation=None):
        """
        :å‚æ•° in_channels: è¾“å…¥é€šé“æ•°
        :å‚æ•° out_channels: è¾“å‡ºé€šé“æ•°
        :å‚æ•° kernel_size: æ ¸å¤§å°
        :å‚æ•° stride: æ­¥é•¿
        :å‚æ•° activation: æ¿€æ´»å±‚ç±»å‹; å¦‚æœæ²¡æœ‰åˆ™ä¸ºNone
        """
        super(ConvolutionalBlock, self).__init__()

        if activation is not None:
            activation = activation.lower()
            assert activation in {'prelu', 'leakyrelu', 'tanh'}

        # å±‚åˆ—è¡¨
        layers = list()

        # 1ä¸ªå·ç§¯å±‚
        layers.append(
            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,
                      padding=kernel_size // 2))

        # 1ä¸ªBNå½’ä¸€åŒ–å±‚
        # if batch_norm is True:
            # layers.append(nn.BatchNorm2d(num_features=out_channels))

        # 1ä¸ªæ¿€æ´»å±‚
        if activation == 'prelu':
            layers.append(nn.PReLU())
        elif activation == 'leakyrelu':
            layers.append(nn.LeakyReLU(0.2))
        elif activation == 'tanh':
            layers.append(nn.Tanh())

        # åˆå¹¶å±‚
        self.conv_block = nn.Sequential(*layers)

    def forward(self, input):
        """
        å‰å‘ä¼ æ’­

        :å‚æ•° input: è¾“å…¥å›¾åƒé›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, in_channels, w, h)
        :è¿”å›: è¾“å‡ºå›¾åƒé›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º(N, out_channels, w, h)
        """
        output = self.conv_block(input)

        return output


class SubPixelConvolutionalBlock(nn.Module):
    """
    å­åƒç´ å·ç§¯æ¨¡å—, åŒ…å«å·ç§¯, åƒç´ æ¸…æ´—å’Œæ¿€æ´»å±‚.
    """

    def __init__(self, kernel_size=3, n_channels=64, scaling_factor=2):
        """
        :å‚æ•° kernel_size: å·ç§¯æ ¸å¤§å°
        :å‚æ•° n_channels: è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°
        :å‚æ•° scaling_factor: æ”¾å¤§æ¯”ä¾‹
        """
        super(SubPixelConvolutionalBlock, self).__init__()

        # é¦–å…ˆé€šè¿‡å·ç§¯å°†é€šé“æ•°æ‰©å±•ä¸º scaling factor^2 å€
        self.conv = nn.Conv2d(in_channels=n_channels, out_channels=n_channels * (scaling_factor ** 2),
                              kernel_size=kernel_size, padding=kernel_size // 2)
        # è¿›è¡Œåƒç´ æ¸…æ´—ï¼Œåˆå¹¶ç›¸å…³é€šé“æ•°æ®
        self.pixel_shuffle = nn.PixelShuffle(upscale_factor=scaling_factor)
        # æœ€åæ·»åŠ æ¿€æ´»å±‚
        self.prelu = nn.PReLU()

    def forward(self, input):
        """
        å‰å‘ä¼ æ’­.

        :å‚æ•° input: è¾“å…¥å›¾åƒæ•°æ®é›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º(N, n_channels, w, h)
        :è¿”å›: è¾“å‡ºå›¾åƒæ•°æ®é›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, n_channels, w * scaling factor, h * scaling factor)
        """
        output = self.conv(input)  # (N, n_channels * scaling factor^2, w, h)
        output = self.pixel_shuffle(output)  # (N, n_channels, w * scaling factor, h * scaling factor)
        output = self.prelu(output)  # (N, n_channels, w * scaling factor, h * scaling factor)

        return output


class ResidualBlock(nn.Module):
    """
    æ®‹å·®æ¨¡å—, åŒ…å«ä¸¤ä¸ªå·ç§¯æ¨¡å—å’Œä¸€ä¸ªè·³è¿.
    """

    def __init__(self, kernel_size=3, n_channels=64):
        """
        :å‚æ•° kernel_size: æ ¸å¤§å°
        :å‚æ•° n_channels: è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°ï¼ˆç”±äºæ˜¯ResNetç½‘ç»œï¼Œéœ€è¦åšè·³è¿ï¼Œå› æ­¤è¾“å…¥å’Œè¾“å‡ºé€šé“æ•°æ˜¯ä¸€è‡´çš„ï¼‰
        """
        super(ResidualBlock, self).__init__()

        # ç¬¬ä¸€ä¸ªå·ç§¯å—
        self.conv_block1 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,
                                            activation='PReLu')

        # ç¬¬äºŒä¸ªå·ç§¯å—
        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,
                                              activation=None)

    def forward(self, input):
        """
        å‰å‘ä¼ æ’­.

        :å‚æ•° input: è¾“å…¥å›¾åƒé›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, n_channels, w, h)
        :è¿”å›: è¾“å‡ºå›¾åƒé›†ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, n_channels, w, h)
        """
        residual = input  # (N, n_channels, w, h)
        output = self.conv_block1(input)  # (N, n_channels, w, h)
        output = self.conv_block2(output)  # (N, n_channels, w, h)
        output = output + residual  # (N, n_channels, w, h)

        return output

class RRDBBlock(nn.Module):
    """

    """
    def __init__(self, in_channels=64, out_channels=64, kernel_size=3):
        super(RRDBBlock, self).__init__()
        """"5ä¸ªå·ç§¯å±‚ï¼Œ4ä¸ªæ¿€æ´»å±‚"""

        self.conv1 = ConvolutionalBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, activation=None)
        self.conv2 = ConvolutionalBlock(in_channels=in_channels + out_channels, out_channels=out_channels,kernel_size=kernel_size, activation=None)
        self.conv3 = ConvolutionalBlock(in_channels=in_channels + 2 * out_channels, out_channels=out_channels, kernel_size=kernel_size, activation=None)
        self.conv4 = ConvolutionalBlock(in_channels=in_channels + 3 * out_channels, out_channels=out_channels, kernel_size=kernel_size, activation=None)
        self.conv5 = ConvolutionalBlock(in_channels=in_channels + 4 * out_channels, out_channels=out_channels, kernel_size=kernel_size, activation=None)
        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)


    """
    å‚è€ƒESRGANè®ºæ–‡ï¼Œresidual scaling parameter è®¾ç½®ä¸º0.2
    """
    def forward(self,x):
        x1 = self.lrelu(self.conv1(x))
        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))
        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))
        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 * 0.2 + x # error fixed due to out_channels
#å¹²å•¥
#æŠ¥é”™äº†
#ğŸæ–‡ï¼ï¼ï¼
#ohi! ç»™æˆ‘ä¸ªæŸœå­
#4090å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆ
# å¯¹æ–¹æ­£åœ¨æ§åˆ¶ï¼Œæ— æ³•ä½¿ç”¨é¼ æ ‡ï¼è°ç”¨ä¸äº†
# 4090
""" 4090
ç»™æˆ‘4090ï¼



"""
class RRDB(nn.Module):
    """
    å‚è€ƒSERGANè®ºæ–‡è®¾è®¡ï¼Œç»“æ„ä¸Šç›¸å½“äºæ›¿æ¢åŸæ¥çš„Residual Block
    """
    def __init__(self, in_channels, out_channels=32):
        super(RRDB,self).__init__()
        self.RDB1 = RRDBBlock(in_channels, out_channels)
        self.RDB2 = RRDBBlock(in_channels, out_channels)
        self.RDB3 = RRDBBlock(in_channels, out_channels)
    """åŒ…å«3ä¸ªRRDB Block"""
    def forward(self,x):
        out = self.RDB1(x)
        out = self.RDB2(out)
        out = self.RDB3(out)
        return out * 0.2 + x

class SRResNet(nn.Module):
    """
    SRResNetæ¨¡å‹
    """

    def __init__(self, large_kernel_size=9, small_kernel_size=3, n_channels=64, n_blocks=16, scaling_factor=4):
        """
        :å‚æ•° large_kernel_size: ç¬¬ä¸€å±‚å·ç§¯å’Œæœ€åä¸€å±‚å·ç§¯æ ¸å¤§å°
        :å‚æ•° small_kernel_size: ä¸­é—´å±‚å·ç§¯æ ¸å¤§å°
        :å‚æ•° n_channels: ä¸­é—´å±‚é€šé“æ•°
        :å‚æ•° n_blocks: æ®‹å·®æ¨¡å—æ•°
        :å‚æ•° scaling_factor: æ”¾å¤§æ¯”ä¾‹
        """
        super(SRResNet, self).__init__()

        # æ”¾å¤§æ¯”ä¾‹å¿…é¡»ä¸º 2ã€ 4 æˆ– 8
        scaling_factor = int(scaling_factor)
        assert scaling_factor in {2, 4, 8}, "æ”¾å¤§æ¯”ä¾‹å¿…é¡»ä¸º 2ã€ 4 æˆ– 8!"

        # ç¬¬ä¸€ä¸ªå·ç§¯å—
        self.conv_block1 = ConvolutionalBlock(in_channels=3, out_channels=n_channels, kernel_size=large_kernel_size,
                                              activation='PReLu')

        # ä¸€ç³»åˆ—æ®‹å·®æ¨¡å—, æ¯ä¸ªæ®‹å·®æ¨¡å—åŒ…å«ä¸€ä¸ªè·³è¿æ¥
        # æ›¿æ¢ä¸ºResidual in Residual Dense Block
        self.residual_blocks = nn.Sequential(
            *[RRDBBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=3) for i in range(n_blocks)])

        # ç¬¬äºŒä¸ªå·ç§¯å—
        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,
                                              kernel_size=small_kernel_size,
                                              activation=None)

        # æ”¾å¤§é€šè¿‡å­åƒç´ å·ç§¯æ¨¡å—å®ç°, æ¯ä¸ªæ¨¡å—æ”¾å¤§ä¸¤å€
        n_subpixel_convolution_blocks = int(math.log2(scaling_factor))
        self.subpixel_convolutional_blocks = nn.Sequential(
            *[SubPixelConvolutionalBlock(kernel_size=small_kernel_size, n_channels=n_channels, scaling_factor=2) for i
              in range(n_subpixel_convolution_blocks)])

        # æœ€åä¸€ä¸ªå·ç§¯æ¨¡å—
        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=3, kernel_size=large_kernel_size,
                                              activation='Tanh')

    def forward(self, lr_imgs):
        """
        å‰å‘ä¼ æ’­.

        :å‚æ•° lr_imgs: ä½åˆ†è¾¨ç‡è¾“å…¥å›¾åƒé›†, å¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, 3, w, h)
        :è¿”å›: é«˜åˆ†è¾¨ç‡è¾“å‡ºå›¾åƒé›†, å¼ é‡è¡¨ç¤ºï¼Œ å¤§å°ä¸º (N, 3, w * scaling factor, h * scaling factor)
        """
        output = self.conv_block1(lr_imgs)  # (16, 3, 24, 24)
        residual = output  # (16, 64, 24, 24)
        output = self.residual_blocks(output)  # (16, 64, 24, 24)
        output = self.conv_block2(output)  # (16, 64, 24, 24)
        output = output + residual  # (16, 64, 24, 24)
        output = self.subpixel_convolutional_blocks(output)  # (16, 64, 24 * 4, 24 * 4)
        sr_imgs = self.conv_block3(output)  # (16, 3, 24 * 4, 24 * 4)

        return sr_imgs


class Generator(nn.Module):
    """
    ç”Ÿæˆå™¨æ¨¡å‹ï¼Œå…¶ç»“æ„ä¸SRResNetå®Œå…¨ä¸€è‡´.
    """

    def __init__(self, large_kernel_size=9, small_kernel_size=3, n_channels=64, n_blocks=16, scaling_factor=4):
        """
        å‚æ•° large_kernel_sizeï¼šç¬¬ä¸€å±‚å’Œæœ€åä¸€å±‚å·ç§¯æ ¸å¤§å°
        å‚æ•° small_kernel_sizeï¼šä¸­é—´å±‚å·ç§¯æ ¸å¤§å°
        å‚æ•° n_channelsï¼šä¸­é—´å±‚å·ç§¯é€šé“æ•°
        å‚æ•° n_blocks: æ®‹å·®æ¨¡å—æ•°é‡
        å‚æ•° scaling_factor: æ”¾å¤§æ¯”ä¾‹
        """
        super(Generator, self).__init__()
        self.net = SRResNet(large_kernel_size=large_kernel_size, small_kernel_size=small_kernel_size,
                            n_channels=n_channels, n_blocks=n_blocks, scaling_factor=scaling_factor)

    def forward(self, lr_imgs):
        """
        å‰å‘ä¼ æ’­.

        å‚æ•° lr_imgs: ä½ç²¾åº¦å›¾åƒ (N, 3, w, h)
        è¿”å›: è¶…åˆ†é‡å»ºå›¾åƒ (N, 3, w * scaling factor, h * scaling factor)
        """

        sr_imgs = self.net(lr_imgs)  # (N, n_channels, w * scaling factor, h * scaling factor)

        return sr_imgs


class Discriminator(nn.Module):
    """
    SRGANåˆ¤åˆ«å™¨
    """

    def __init__(self, kernel_size=3, n_channels=64, n_blocks=8, fc_size=1024):
        """
        å‚æ•° kernel_size: æ‰€æœ‰å·ç§¯å±‚çš„æ ¸å¤§å°
        å‚æ•° n_channels: åˆå§‹å·ç§¯å±‚è¾“å‡ºé€šé“æ•°, åé¢æ¯éš”ä¸€ä¸ªå·ç§¯å±‚é€šé“æ•°ç¿»å€
        å‚æ•° n_blocks: å·ç§¯å—æ•°é‡
        å‚æ•° fc_size: å…¨è¿æ¥å±‚è¿æ¥æ•°
        """
        super(Discriminator, self).__init__()

        in_channels = 3

        # å·ç§¯ç³»åˆ—ï¼Œå‚ç…§è®ºæ–‡SRGANè¿›è¡Œè®¾è®¡
        conv_blocks = list()
        for i in range(n_blocks):
            out_channels = (n_channels if i is 0 else in_channels * 2) if i % 2 is 0 else in_channels
            conv_blocks.append(
                ConvolutionalBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                   stride=1 if i % 2 is 0 else 2, activation='LeakyReLu'))
            in_channels = out_channels
        self.conv_blocks = nn.Sequential(*conv_blocks)

        # å›ºå®šè¾“å‡ºå¤§å°
        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))

        self.fc1 = nn.Linear(out_channels * 6 * 6, fc_size)

        self.leaky_relu = nn.LeakyReLU(0.2)

        self.fc2 = nn.Linear(1024, 1)

        # æœ€åä¸éœ€è¦æ·»åŠ sigmoidå±‚ï¼Œå› ä¸ºPyTorchçš„nn.BCEWithLogitsLoss()å·²ç»åŒ…å«äº†è¿™ä¸ªæ­¥éª¤

    def forward(self, imgs):
        """
        å‰å‘ä¼ æ’­.

        å‚æ•° imgs: ç”¨äºä½œåˆ¤åˆ«çš„åŸå§‹é«˜æ¸…å›¾æˆ–è¶…åˆ†é‡å»ºå›¾ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º(N, 3, w * scaling factor, h * scaling factor)
        è¿”å›: ä¸€ä¸ªè¯„åˆ†å€¼ï¼Œ ç”¨äºåˆ¤æ–­ä¸€å‰¯å›¾åƒæ˜¯å¦æ˜¯é«˜æ¸…å›¾, å¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N)
        """
        batch_size = imgs.size(0)
        output = self.conv_blocks(imgs)
        output = self.adaptive_pool(output)
        output = self.fc1(output.view(batch_size, -1))
        output = self.leaky_relu(output)
        logit = self.fc2(output)

        return logit


class TruncatedVGG19(nn.Module):
    """
    truncated VGG19ç½‘ç»œï¼Œç”¨äºè®¡ç®—VGGç‰¹å¾ç©ºé—´çš„MSEæŸå¤±
    """

    def __init__(self, i, j):
        """
        :å‚æ•° i: ç¬¬ i ä¸ªæ± åŒ–å±‚
        :å‚æ•° j: ç¬¬ j ä¸ªå·ç§¯å±‚
        """
        super(TruncatedVGG19, self).__init__()

        # åŠ è½½é¢„è®­ç»ƒçš„VGGæ¨¡å‹
        vgg19 = torchvision.models.vgg19(
            pretrained=True)  # C:\Users\Administrator/.cache\torch\checkpoints\vgg19-dcbb9e9d.pth

        maxpool_counter = 0
        conv_counter = 0
        truncate_at = 0
        # è¿­ä»£æœç´¢
        for layer in vgg19.features.children():
            truncate_at += 1

            # ç»Ÿè®¡
            if isinstance(layer, nn.Conv2d):
                conv_counter += 1
            if isinstance(layer, nn.MaxPool2d):
                maxpool_counter += 1
                conv_counter = 0

            # æˆªæ–­ä½ç½®åœ¨ç¬¬(i-1)ä¸ªæ± åŒ–å±‚ä¹‹åï¼ˆç¬¬ i ä¸ªæ± åŒ–å±‚ä¹‹å‰ï¼‰çš„ç¬¬ j ä¸ªå·ç§¯å±‚
            if maxpool_counter == i - 1 and conv_counter == j:
                break

        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶
        assert maxpool_counter == i - 1 and conv_counter == j, "å½“å‰ i=%d ã€ j=%d ä¸æ»¡è¶³ VGG19 æ¨¡å‹ç»“æ„" % (
            i, j)

        # æˆªå–ç½‘ç»œ
        self.truncated_vgg19 = nn.Sequential(*list(vgg19.features.children())[:truncate_at + 1])

    def forward(self, input):
        """
        å‰å‘ä¼ æ’­
        å‚æ•° input: é«˜æ¸…åŸå§‹å›¾æˆ–è¶…åˆ†é‡å»ºå›¾ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, 3, w * scaling factor, h * scaling factor)
        è¿”å›: VGG19ç‰¹å¾å›¾ï¼Œå¼ é‡è¡¨ç¤ºï¼Œå¤§å°ä¸º (N, feature_map_channels, feature_map_w, feature_map_h)
        """
        output = self.truncated_vgg19(input)  # (N, feature_map_channels, feature_map_w, feature_map_h)

        return output



